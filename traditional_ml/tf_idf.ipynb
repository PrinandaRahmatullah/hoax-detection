{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recognized-gilbert",
   "metadata": {},
   "source": [
    "# Hoax Detection Using Traditional Machine Learning\n",
    "## Dataset from Satria Data 2020 - Big Data Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "offensive-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pickle\n",
    "from pandarallel import pandarallel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from string import punctuation\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "final-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/prinanda/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "casual-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# multiprocessing Initialization\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enabling-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "train_data = pd.read_excel(\"../data/training/DataLatih.xlsx\", engine=\"openpyxl\")\n",
    "test_data = pd.read_excel(\"../data/testing/DataUji.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "falling-identification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>nama file gambar</th>\n",
       "      <th>judul_translate</th>\n",
       "      <th>narasi_translate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-17 00:00:00</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "      <td>A caller to a radio talk show recently shared ...</td>\n",
       "      <td>71.jpg</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "      <td>Seorang penelepon ke talk show radio baru-baru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17 00:00:00</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
       "      <td>461.png</td>\n",
       "      <td>Instruksi Gubernur Jateng TENTANG penilangan B...</td>\n",
       "      <td>Yth.Seluruh Anggota Anggota Grup Sesuai Instru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-13 00:00:00</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
       "      <td>495.png</td>\n",
       "      <td>Foto Jim Rohn: Jokowi Adalah Presiden Terbaik ...</td>\n",
       "      <td>Jokowi Adalah Presiden Terbaik dlm Sejarah ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-08 00:00:00</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
       "      <td>550.png</td>\n",
       "      <td>Suami Bukan politik, TAPI Kenyataan Pak Jokowi...</td>\n",
       "      <td>Maaf Mas2 Dan Mbak2, Penyanyi Bukan politik, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-24 00:00:00</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin</td>\n",
       "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
       "      <td>681.jpg</td>\n",
       "      <td>Foto Kadrun kalo lihat foto Penyanyi Panas Dingin</td>\n",
       "      <td>Kadrun kalo lihat foto Penyanyi Panas Dingin. .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  label              tanggal  \\\n",
       "0   71      1  2020-08-17 00:00:00   \n",
       "1  461      1  2020-07-17 00:00:00   \n",
       "2  495      1  2020-07-13 00:00:00   \n",
       "3  550      1  2020-07-08 00:00:00   \n",
       "4  681      1  2020-06-24 00:00:00   \n",
       "\n",
       "                                               judul  \\\n",
       "0  Pemakaian Masker Menyebabkan Penyakit Legionna...   \n",
       "1  Instruksi Gubernur Jateng tentang penilangan  ...   \n",
       "2  Foto Jim Rohn: Jokowi adalah presiden terbaik ...   \n",
       "3  ini bukan politik, tapi kenyataan Pak Jokowi b...   \n",
       "4       Foto Kadrun kalo lihat foto ini panas dingin   \n",
       "\n",
       "                                              narasi nama file gambar  \\\n",
       "0  A caller to a radio talk show recently shared ...           71.jpg   \n",
       "1  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...          461.png   \n",
       "2  Jokowi adalah presiden terbaik dlm sejarah ban...          495.png   \n",
       "3  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...          550.png   \n",
       "4        Kadrun kalo lihat foto ini panas dingin . .          681.jpg   \n",
       "\n",
       "                                     judul_translate  \\\n",
       "0  Pemakaian Masker Menyebabkan Penyakit Legionna...   \n",
       "1  Instruksi Gubernur Jateng TENTANG penilangan B...   \n",
       "2  Foto Jim Rohn: Jokowi Adalah Presiden Terbaik ...   \n",
       "3  Suami Bukan politik, TAPI Kenyataan Pak Jokowi...   \n",
       "4  Foto Kadrun kalo lihat foto Penyanyi Panas Dingin   \n",
       "\n",
       "                                    narasi_translate  \n",
       "0  Seorang penelepon ke talk show radio baru-baru...  \n",
       "1  Yth.Seluruh Anggota Anggota Grup Sesuai Instru...  \n",
       "2  Jokowi Adalah Presiden Terbaik dlm Sejarah ban...  \n",
       "3  Maaf Mas2 Dan Mbak2, Penyanyi Bukan politik, T...  \n",
       "4    Kadrun kalo lihat foto Penyanyi Panas Dingin. .  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "serious-academy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>nama file gambar</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>judul_translate</th>\n",
       "      <th>narasi_translate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238057</td>\n",
       "      <td>2020-07-13 00:00:00</td>\n",
       "      <td>Narasi Tito Karnavian Berideologi Komunis Kare...</td>\n",
       "      <td>TITO KARNIVAN ITU BERIDIOLOGI KOMUNIS DIA BISA...</td>\n",
       "      <td>238057.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Narasi Tito Karnavian Berideologi Komunis KARE...</td>\n",
       "      <td>TITO KARNIVAN ITU beridiologi Komunis DIA BISA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238158</td>\n",
       "      <td>2020-07-06 00:00:00</td>\n",
       "      <td>Anies: Seberat beratnya Pekerjaan Akan terasa ...</td>\n",
       "      <td>Seberat beratnya Pekerjaan Akan terasa ringan ...</td>\n",
       "      <td>238158.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anies: seberat beratnya Pekerjaan Akan terasa ...</td>\n",
       "      <td>Seberat beratnya Pekerjaan Akan terasa Anda Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238865</td>\n",
       "      <td>2020-04-22 00:00:00</td>\n",
       "      <td>Hindu di india Melemparkan Patung Buatan Merek...</td>\n",
       "      <td>Hindu di india melemparkan patung buatan merek...</td>\n",
       "      <td>238865.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hindu di india Melemparkan Patung Buatan Merek...</td>\n",
       "      <td>Hindu di india melemparkan patung Buatan merek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248298</td>\n",
       "      <td>2019-10-22 00:00:00</td>\n",
       "      <td>RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...</td>\n",
       "      <td>Mulai Hari ini di RSCM mulai diPraktekkan Peny...</td>\n",
       "      <td>248298.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RSCM praktekkan penyedotan Plug Vena / Saluran...</td>\n",
       "      <td>Mulai Hari Penyanyi di RSCM Mulai diPraktekkan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255176</td>\n",
       "      <td>2020-05-01 00:00:00</td>\n",
       "      <td>Permohonan Kelonggaran Angsuran ke OJK</td>\n",
       "      <td>Untuk sekedar info, Bagi anda yg punya ansuran...</td>\n",
       "      <td>255176.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Permohonan Kelonggaran Angsuran Ke OJK</td>\n",
       "      <td>Untuk Sekedar info, Bagi Andari yg Punya ansur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID              tanggal  \\\n",
       "0  238057  2020-07-13 00:00:00   \n",
       "1  238158  2020-07-06 00:00:00   \n",
       "2  238865  2020-04-22 00:00:00   \n",
       "3  248298  2019-10-22 00:00:00   \n",
       "4  255176  2020-05-01 00:00:00   \n",
       "\n",
       "                                               judul  \\\n",
       "0  Narasi Tito Karnavian Berideologi Komunis Kare...   \n",
       "1  Anies: Seberat beratnya Pekerjaan Akan terasa ...   \n",
       "2  Hindu di india Melemparkan Patung Buatan Merek...   \n",
       "3  RSCM Praktekkan Penyedotan Plug  Vena/Saluran ...   \n",
       "4             Permohonan Kelonggaran Angsuran ke OJK   \n",
       "\n",
       "                                              narasi nama file gambar  \\\n",
       "0  TITO KARNIVAN ITU BERIDIOLOGI KOMUNIS DIA BISA...       238057.jpg   \n",
       "1  Seberat beratnya Pekerjaan Akan terasa ringan ...       238158.jpg   \n",
       "2  Hindu di india melemparkan patung buatan merek...       238865.jpg   \n",
       "3  Mulai Hari ini di RSCM mulai diPraktekkan Peny...       248298.jpg   \n",
       "4  Untuk sekedar info, Bagi anda yg punya ansuran...       255176.jpg   \n",
       "\n",
       "   Unnamed: 5                                    judul_translate  \\\n",
       "0         NaN  Narasi Tito Karnavian Berideologi Komunis KARE...   \n",
       "1         NaN  Anies: seberat beratnya Pekerjaan Akan terasa ...   \n",
       "2         NaN  Hindu di india Melemparkan Patung Buatan Merek...   \n",
       "3         NaN  RSCM praktekkan penyedotan Plug Vena / Saluran...   \n",
       "4         NaN             Permohonan Kelonggaran Angsuran Ke OJK   \n",
       "\n",
       "                                    narasi_translate  \n",
       "0  TITO KARNIVAN ITU beridiologi Komunis DIA BISA...  \n",
       "1  Seberat beratnya Pekerjaan Akan terasa Anda Ri...  \n",
       "2  Hindu di india melemparkan patung Buatan merek...  \n",
       "3  Mulai Hari Penyanyi di RSCM Mulai diPraktekkan...  \n",
       "4  Untuk Sekedar info, Bagi Andari yg Punya ansur...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-unknown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "august-iceland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reconstruct train dataframe\n",
    "train_df = pd.DataFrame()\n",
    "train_df[\"konten\"] = train_data[\"judul_translate\"] + \" \" + train_data[\"narasi_translate\"]\n",
    "train_df[\"Class\"] = train_data[\"label\"]\n",
    "\n",
    "# Reconstruct test dataframe\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"ID\"] = test_data[\"ID\"]\n",
    "test_df[\"konten\"] = test_data[\"judul_translate\"] + \" \" + test_data[\"narasi_translate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "minor-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stopword list, indonesia\n",
    "STOPWORDS = set(StopWordRemoverFactory().get_stop_words() + stopwords.words('english'))\n",
    "\n",
    "# define list kata singkat\n",
    "KATASINGKAT = {\"dlm\":\"dalam\", \"gw\":\"saya\", \"yg\":\"yang\", \"lu\":\"kamu\", \"dkt\":\"dekat\", \"kalo\":\"kalau\", \"n\":\"and\"}\n",
    "\n",
    "# define stemmer sastrawi for Indonesia\n",
    "stemmer_ind = StemmerFactory().create_stemmer()\n",
    "stemmer_eng = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comparable-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of preprocessing\n",
    "\n",
    "def remove_kata_singkat(word):\n",
    "    if word in list(KATASINGKAT.keys()):\n",
    "        return KATASINGKAT.get(word)\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "def normalize_word(row):\n",
    "    # remove punctuation\n",
    "    konten = re.sub(r'[^a-zA-Z\\s]', '', row.konten, re.I|re.A)\n",
    "    \n",
    "    # case folding and remove kata singkat\n",
    "    konten = \" \".join([remove_kata_singkat(word.lower()).strip() for word in nltk.word_tokenize(konten)])\n",
    "    \n",
    "    # remove stopword and number\n",
    "    konten = \" \".join([word for word in nltk.word_tokenize(konten) if word not in punctuation and word.isalpha() and word not in STOPWORDS])\n",
    "    \n",
    "    # stemming\n",
    "    konten = stemmer_ind.stem(konten)\n",
    "    konten = stemmer_eng.stem(konten)\n",
    "    \n",
    "    # final assignment\n",
    "    row.konten = konten\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply preprocess to dataframe\n",
    "# train_df = train_df.apply(normalize_word, axis=1)\n",
    "# test_df = test_df.apply(normalize_word, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arbitrary-empire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3e6be138a548f4b4eb77ac80851633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1058), Label(value='0 / 1058'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parallel preprocess to dataframe with progressbar\n",
    "train_df = train_df.parallel_apply(normalize_word, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mysterious-drive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06483784435740f1be9bf57311e143e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=118), Label(value='0 / 118'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = test_df.parallel_apply(normalize_word, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "magnetic-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>konten</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pakai masker sebab sakit legionnaires orang te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instruksi gubernur jateng tilang masker muka u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foto jim rohn jokowi presiden baik sejarah ban...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suami bukan politik nyata pak jokowi hasil pul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foto kadrun kalau lihat foto nyanyi panas ding...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              konten  Class\n",
       "0  pakai masker sebab sakit legionnaires orang te...      1\n",
       "1  instruksi gubernur jateng tilang masker muka u...      1\n",
       "2  foto jim rohn jokowi presiden baik sejarah ban...      1\n",
       "3  suami bukan politik nyata pak jokowi hasil pul...      1\n",
       "4  foto kadrun kalau lihat foto nyanyi panas ding...      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nonprofit-tolerance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>konten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238057</td>\n",
       "      <td>narasi tito karnavian ideologi komunis pernah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238158</td>\n",
       "      <td>anies berat berat kerja asa ringan bila kerja ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238865</td>\n",
       "      <td>hindu india lempar patung buat laut tolong cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248298</td>\n",
       "      <td>rscm praktek sedot plug vena salur darah mulai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255176</td>\n",
       "      <td>mohon longgar angsur ojk dar info andar punya ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                             konten\n",
       "0  238057  narasi tito karnavian ideologi komunis pernah ...\n",
       "1  238158  anies berat berat kerja asa ringan bila kerja ...\n",
       "2  238865  hindu india lempar patung buat laut tolong cor...\n",
       "3  248298  rscm praktek sedot plug vena salur darah mulai...\n",
       "4  255176  mohon longgar angsur ojk dar info andar punya ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-flood",
   "metadata": {},
   "source": [
    "## Feature Extraction Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reliable-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# konten_all = train_df.loc[:,\"konten\"].append(test_df.loc[:,\"konten\"], ignore_index=True)\n",
    "konten_train = train_df.loc[:,\"konten\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acting-inspiration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       pakai masker sebab sakit legionnaires orang te...\n",
       "1       instruksi gubernur jateng tilang masker muka u...\n",
       "2       foto jim rohn jokowi presiden baik sejarah ban...\n",
       "3       suami bukan politik nyata pak jokowi hasil pul...\n",
       "4       foto kadrun kalau lihat foto nyanyi panas ding...\n",
       "                              ...                        \n",
       "4226    kpk larang bawa brimob senjata masuk gedung dp...\n",
       "4227    foto jabat uang bawah palu arit jangan mau ali...\n",
       "4228    gambar denny siregar musuh warga tasikmalaya b...\n",
       "4229    kaesang bapak kesederhaan nipu rakyat indonesi...\n",
       "4230    laser termometer gun rusak struktur otak nolak...\n",
       "Name: konten, Length: 4231, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# konten_all\n",
    "konten_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "impossible-examination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaamiin</th>\n",
       "      <th>aaamiinn</th>\n",
       "      <th>aac</th>\n",
       "      <th>aaj</th>\n",
       "      <th>aalaamiin</th>\n",
       "      <th>aalamiin</th>\n",
       "      <th>aamiiin</th>\n",
       "      <th>aamiin</th>\n",
       "      <th>aamiinkan</th>\n",
       "      <th>...</th>\n",
       "      <th>zuhur</th>\n",
       "      <th>zulhasan</th>\n",
       "      <th>zulkarnaen</th>\n",
       "      <th>zulkarnain</th>\n",
       "      <th>zulkieflimansyah</th>\n",
       "      <th>zulkifli</th>\n",
       "      <th>zulkifliemansyah</th>\n",
       "      <th>zumi</th>\n",
       "      <th>zurina</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4231 rows × 14036 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaamiin  aaamiinn  aac  aaj  aalaamiin  aalamiin  aamiiin  aamiin  \\\n",
       "0     0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "1     0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "2     0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "3     0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "4     0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "...   ...      ...       ...  ...  ...        ...       ...      ...     ...   \n",
       "4226  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "4227  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "4228  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "4229  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "4230  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "\n",
       "      aamiinkan  ...  zuhur  zulhasan  zulkarnaen  zulkarnain  \\\n",
       "0           0.0  ...    0.0       0.0         0.0         0.0   \n",
       "1           0.0  ...    0.0       0.0         0.0         0.0   \n",
       "2           0.0  ...    0.0       0.0         0.0         0.0   \n",
       "3           0.0  ...    0.0       0.0         0.0         0.0   \n",
       "4           0.0  ...    0.0       0.0         0.0         0.0   \n",
       "...         ...  ...    ...       ...         ...         ...   \n",
       "4226        0.0  ...    0.0       0.0         0.0         0.0   \n",
       "4227        0.0  ...    0.0       0.0         0.0         0.0   \n",
       "4228        0.0  ...    0.0       0.0         0.0         0.0   \n",
       "4229        0.0  ...    0.0       0.0         0.0         0.0   \n",
       "4230        0.0  ...    0.0       0.0         0.0         0.0   \n",
       "\n",
       "      zulkieflimansyah  zulkifli  zulkifliemansyah  zumi  zurina  Class  \n",
       "0                  0.0       0.0               0.0   0.0     0.0      1  \n",
       "1                  0.0       0.0               0.0   0.0     0.0      1  \n",
       "2                  0.0       0.0               0.0   0.0     0.0      1  \n",
       "3                  0.0       0.0               0.0   0.0     0.0      1  \n",
       "4                  0.0       0.0               0.0   0.0     0.0      1  \n",
       "...                ...       ...               ...   ...     ...    ...  \n",
       "4226               0.0       0.0               0.0   0.0     0.0      1  \n",
       "4227               0.0       0.0               0.0   0.0     0.0      1  \n",
       "4228               0.0       0.0               0.0   0.0     0.0      1  \n",
       "4229               0.0       0.0               0.0   0.0     0.0      1  \n",
       "4230               0.0       0.0               0.0   0.0     0.0      1  \n",
       "\n",
       "[4231 rows x 14036 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=0.0)\n",
    "\n",
    "# tokenize and build vocab0\n",
    "tfidf_matrix = tfidf_vectorizer.fit(konten_train)\n",
    "\n",
    "# encode training entry\n",
    "tfidf_matrix = tfidf_vectorizer.transform(train_df.loc[:,\"konten\"])\n",
    "tfidf_matrix = tfidf_matrix.toarray()\n",
    "\n",
    "# get all unique words in the corpus\n",
    "vocab = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# show document feature vectors\n",
    "training_df = pd.DataFrame(tfidf_matrix, columns=vocab)\n",
    "training_df[\"Class\"] = train_df.loc[:,\"Class\"]\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "running-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaamiin</th>\n",
       "      <th>aaamiinn</th>\n",
       "      <th>aac</th>\n",
       "      <th>aaj</th>\n",
       "      <th>aalaamiin</th>\n",
       "      <th>aalamiin</th>\n",
       "      <th>aamiiin</th>\n",
       "      <th>aamiin</th>\n",
       "      <th>aamiinkan</th>\n",
       "      <th>...</th>\n",
       "      <th>zuey</th>\n",
       "      <th>zuhur</th>\n",
       "      <th>zulhasan</th>\n",
       "      <th>zulkarnaen</th>\n",
       "      <th>zulkarnain</th>\n",
       "      <th>zulkieflimansyah</th>\n",
       "      <th>zulkifli</th>\n",
       "      <th>zulkifliemansyah</th>\n",
       "      <th>zumi</th>\n",
       "      <th>zurina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 14035 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaamiin  aaamiinn  aac  aaj  aalaamiin  aalamiin  aamiiin  aamiin  \\\n",
       "0    0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "1    0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "2    0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "3    0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "4    0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "..   ...      ...       ...  ...  ...        ...       ...      ...     ...   \n",
       "465  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "466  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "467  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "468  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "469  0.0      0.0       0.0  0.0  0.0        0.0       0.0      0.0     0.0   \n",
       "\n",
       "     aamiinkan  ...  zuey  zuhur  zulhasan  zulkarnaen  zulkarnain  \\\n",
       "0          0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "1          0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "2          0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "3          0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "4          0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "..         ...  ...   ...    ...       ...         ...         ...   \n",
       "465        0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "466        0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "467        0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "468        0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "469        0.0  ...   0.0    0.0       0.0         0.0         0.0   \n",
       "\n",
       "     zulkieflimansyah  zulkifli  zulkifliemansyah  zumi  zurina  \n",
       "0                 0.0       0.0               0.0   0.0     0.0  \n",
       "1                 0.0       0.0               0.0   0.0     0.0  \n",
       "2                 0.0       0.0               0.0   0.0     0.0  \n",
       "3                 0.0       0.0               0.0   0.0     0.0  \n",
       "4                 0.0       0.0               0.0   0.0     0.0  \n",
       "..                ...       ...               ...   ...     ...  \n",
       "465               0.0       0.0               0.0   0.0     0.0  \n",
       "466               0.0       0.0               0.0   0.0     0.0  \n",
       "467               0.0       0.0               0.0   0.0     0.0  \n",
       "468               0.0       0.0               0.0   0.0     0.0  \n",
       "469               0.0       0.0               0.0   0.0     0.0  \n",
       "\n",
       "[470 rows x 14035 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode testing entry\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(test_df.loc[:,\"konten\"])\n",
    "tfidf_matrix_test = tfidf_matrix_test.toarray()\n",
    "\n",
    "# show document feature vectors\n",
    "testing_df = pd.DataFrame(tfidf_matrix_test, columns=vocab)\n",
    "testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dirty-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X =  training_df.drop(\"Class\", axis=1)\n",
    "y =  training_df[\"Class\"]\n",
    "\n",
    "X_test = testing_df.copy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pretty-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3384, 14035), (847, 14035), (3384,), (847,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-values",
   "metadata": {},
   "source": [
    "## Build and Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-antique",
   "metadata": {},
   "source": [
    "### 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "transsexual-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25       152\n",
      "           1       0.84      0.84      0.84       695\n",
      "\n",
      "    accuracy                           0.73       847\n",
      "   macro avg       0.54      0.54      0.54       847\n",
      "weighted avg       0.73      0.73      0.73       847\n",
      "\n",
      "[[ 38 114]\n",
      " [112 583]]\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors= 1)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model as a pickle string.\n",
    "filename = '../model/tfidf_knn_model.pkl'\n",
    "pickle.dump(knn_model,open(filename, 'wb'))\n",
    "  \n",
    "# Load the pickled model\n",
    "knn_from_pickle = pickle.load(open(filename, 'rb'))\n",
    "  \n",
    "# Use the loaded pickled model to make predictions\n",
    "knn_from_pickle.predict(X_test)\n",
    "\n",
    "val_pred_knn = knn_from_pickle.predict(X_val)\n",
    "print(classification_report(y_val, val_pred_knn))\n",
    "print(confusion_matrix(y_val, val_pred_knn, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alien-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "predictions_knn = knn_from_pickle.predict(X_test)\n",
    "result_knn = pd.DataFrame(zip(test_df[\"ID\"], predictions_knn), columns=[\"ID\", \"Prediksi\"])\n",
    "result_knn.to_csv(\"../result/tfidf/result_knn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-township",
   "metadata": {},
   "source": [
    "### 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "express-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.28      0.27       152\n",
      "           1       0.84      0.82      0.83       695\n",
      "\n",
      "    accuracy                           0.73       847\n",
      "   macro avg       0.55      0.55      0.55       847\n",
      "weighted avg       0.74      0.73      0.73       847\n",
      "\n",
      "[[ 43 109]\n",
      " [123 572]]\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model as a pickle string.\n",
    "filename = '../model/tfidf_nb_model.pkl'\n",
    "pickle.dump(nb_model,open(filename, 'wb'))\n",
    "  \n",
    "# Load the pickled model\n",
    "nb_from_pickle = pickle.load(open(filename, 'rb'))\n",
    "  \n",
    "# Use the loaded pickled model to make predictions\n",
    "nb_from_pickle.predict(X_test)\n",
    "\n",
    "val_pred_nb = nb_from_pickle.predict(X_val)\n",
    "print(classification_report(y_val, val_pred_nb))\n",
    "print(confusion_matrix(y_val, val_pred_nb, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "false-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "predictions_nb = nb_from_pickle.predict(X_test)\n",
    "result_nb = pd.DataFrame(zip(test_df[\"ID\"], predictions_nb), columns=[\"ID\", \"Prediksi\"])\n",
    "result_nb.to_csv(\"../result/tfidf/result_nb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-details",
   "metadata": {},
   "source": [
    "### 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sustained-credit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.07      0.13       152\n",
      "           1       0.83      0.99      0.90       695\n",
      "\n",
      "    accuracy                           0.83       847\n",
      "   macro avg       0.72      0.53      0.52       847\n",
      "weighted avg       0.79      0.83      0.76       847\n",
      "\n",
      "[[ 11 141]\n",
      " [  7 688]]\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel=\"rbf\")\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model as a pickle string.\n",
    "filename = '../model/tfidf_svm_model.pkl'\n",
    "pickle.dump(svm_model,open(filename, 'wb'))\n",
    "  \n",
    "# Load the pickled model\n",
    "svm_from_pickle = pickle.load(open(filename, 'rb'))\n",
    "  \n",
    "# Use the loaded pickled model to make predictions\n",
    "svm_from_pickle.predict(X_test)\n",
    "\n",
    "val_pred_svm = svm_from_pickle.predict(X_val)\n",
    "print(classification_report(y_val, val_pred_svm))\n",
    "print(confusion_matrix(y_val, val_pred_svm, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pretty-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "predictions_svm = svm_from_pickle.predict(X_test)\n",
    "results_svm = pd.DataFrame(zip(test_df[\"ID\"], predictions_svm), columns=[\"ID\", \"Prediksi\"])\n",
    "results_svm.to_csv(\"../result/tfidf/result_svm.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
