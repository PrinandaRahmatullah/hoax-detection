{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naked-market",
   "metadata": {},
   "source": [
    "# Hoax Detection Using RNN-LSTM\n",
    "## Dataset from Satria Data 2020 - Big Data Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-morgan",
   "metadata": {},
   "source": [
    "## Covolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-hormone",
   "metadata": {},
   "source": [
    "## Needed Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform image into array\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224, 3))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "\n",
    "# transform single image into array for prediction\n",
    "def single_preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224, 3))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dan preprocess training data\n",
    "def train_data(train_data_path):\n",
    "    print(\"\\n-- PREPARE TRAINING DATA --\")\n",
    "    train_image = []\n",
    "    train_label = []\n",
    "\n",
    "    list_training = list(os.listdir(train_data_path))\n",
    "    label_size = len(list_training)\n",
    "\n",
    "    # CARA 2\n",
    "    # load image from each subject\n",
    "    sub_num = 0\n",
    "    for sub in tqdm(sorted(list_training)):\n",
    "        for photo in (os.listdir(f\"{train_data_path}/{sub}\")):\n",
    "            filename = f\"{train_data_path}/{sub}/{photo}\"\n",
    "            image_out = preprocess_image(filename)\n",
    "\n",
    "            # iamge feature and class in binary\n",
    "            train_image.append(image_out)\n",
    "            train_label.append(sub)\n",
    "        if(sub_num == 0):\n",
    "            np_train = np.array(train_image)\n",
    "        else:\n",
    "            np_train = np.concatenate((np_train, np.array(train_image)))\n",
    "        train_image.clear()\n",
    "        sub_num += 1\n",
    "\n",
    "    # encode train label\n",
    "    le_train = LabelEncoder()\n",
    "    train_label = le_train.fit_transform(train_label)\n",
    "    train_label = to_categorical(train_label, label_size)\n",
    "\n",
    "    # split data\n",
    "    X_train = np_train\n",
    "    y_train = train_label\n",
    "\n",
    "    print(\"Train image list\\t: \", sys.getsizeof(train_image)*len(train_image))\n",
    "    print(\"X_train image np\\t: \", X_train.nbytes)\n",
    "    # train_image.clear()\n",
    "    print(\"Train image list\\t: \", sys.getsizeof(train_image)*len(train_image))\n",
    "    return (X_train, y_train, le_train)\n",
    "\n",
    "\n",
    "# read dan preprocess testing data\n",
    "def test_data(test_data_path):\n",
    "    print(\"\\n-- PREPARE TESTING DATA --\")\n",
    "    test_image = []\n",
    "    test_label = []\n",
    "\n",
    "    list_testing = list(os.listdir(test_data_path))\n",
    "    label_size = len(list_testing)\n",
    "\n",
    "    # CARA 2\n",
    "    # load image from each subject\n",
    "    sub_num = 0\n",
    "    for sub in tqdm(sorted(list_testing)):\n",
    "        for photo in (os.listdir(f\"{test_data_path}/{sub}\")):\n",
    "            filename = f\"{test_data_path}/{sub}/{photo}\"\n",
    "            image_out = preprocess_image(filename)\n",
    "\n",
    "            # iamge feature and class in binary\n",
    "            test_image.append(image_out)\n",
    "            test_label.append(sub)\n",
    "        if(sub_num == 0):\n",
    "            np_test = np.array(test_image)\n",
    "        else:\n",
    "            np_test = np.concatenate((np_test, np.array(test_image)))\n",
    "        test_image.clear()\n",
    "        sub_num += 1\n",
    "\n",
    "    # Encode test label\n",
    "    le_test = LabelEncoder()\n",
    "    test_label = le_test.fit_transform(test_label)\n",
    "    test_label = to_categorical(test_label, label_size)\n",
    "\n",
    "    # split data\n",
    "    X_test = np_test\n",
    "    y_test = test_label\n",
    "\n",
    "    print(\"Test image list\\t: \", sys.getsizeof(test_image)*len(test_image))\n",
    "    print(\"X_test image np\\t: \", X_test.nbytes)\n",
    "    # test_image.clear()\n",
    "    print(\"Test image list\\t: \", sys.getsizeof(test_image)*len(test_image))\n",
    "    return (X_test, y_test, le_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE RESNET-50 MODEL (imported from tensorflow.keras)\n",
    "def resnet50(output_class):\n",
    "    model = ResNet50(classes=output_class, weights=None,\n",
    "                     input_shape=(224, 224, 3))\n",
    "    return model\n",
    "\n",
    "# DEFINE MODEL CALLBACKS\n",
    "def my_callbacks(MODEL_NAME, label_size, image_per_label, EPOCHS, BS):\n",
    "    model_callbacks = [\n",
    "        # EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "        CSVLogger(\n",
    "            filename=f\"../Model/{MODEL_NAME}/history_{MODEL_NAME}_label{label_size}_data{image_per_label}_e{EPOCHS}_bs{BS}.csv\", separator=\",\", append=False),\n",
    "        ModelCheckpoint(\n",
    "            filepath=f\"../Model/{MODEL_NAME}/model_{MODEL_NAME}_label{label_size}_data{image_per_label}_e{EPOCHS}_bs{BS}_val_loss.h5\", monitor=\"val_loss\", save_best_only=True),\n",
    "        ModelCheckpoint(\n",
    "            filepath=f\"../Model/{MODEL_NAME}/model_{MODEL_NAME}_label{label_size}_data{image_per_label}_e{EPOCHS}_bs{BS}_val_accuracy.h5\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "    ]\n",
    "    return model_callbacks\n",
    "\n",
    "# DEFINE LOAD MODEL\n",
    "def load_my_model(MODEL_NAME, label_size, image_per_label, EPOCHS, BS):\n",
    "    model = load_model(\n",
    "        f\"../Model/{MODEL_NAME}/model_{MODEL_NAME}_label{label_size}_data{image_per_label}_e{EPOCHS}_bs{BS}_val_accuracy.h5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Font option\n",
    "title_font = {'weight': 'medium', 'size': 'medium'}\n",
    "axis_font = {'size': 'small'}\n",
    "\n",
    "\n",
    "# Visualize accuracy from training model\n",
    "def visualize_accuracy(Historia, MODEL_NAME, label_size, image_per_label, EPOCHS, BS):\n",
    "    # xlimit\n",
    "    Numero = np.arange(1, EPOCHS+1, 1)\n",
    "\n",
    "    # plot accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(Numero, Historia.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(Numero, Historia.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training and Validation Accuracy on Dataset\", **title_font)\n",
    "    plt.xlabel(\n",
    "        f\"Epoch {EPOCHS} Batch Size {BS} Label {label_size} Data {image_per_label}\", **axis_font)\n",
    "    plt.ylabel(\"Accuracy\", **axis_font)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.savefig(\n",
    "        f\"../Model/{MODEL_NAME}/figure_accuracy_{MODEL_NAME}_label{label_size}_data{image_per_label}_e{EPOCHS}_bs{BS}.png\", dpi=600)\n",
    "\n",
    "\n",
    "# Visualize loss from training model\n",
    "def visualize_loss(Historia, MODEL_NAME, label_size, image_per_label, EPOCHS, BS):\n",
    "    # xlimit\n",
    "    Numero = np.arange(1, EPOCHS+1, 1)\n",
    "\n",
    "    # plot loss\n",
    "    plt.figure()\n",
    "    plt.plot(Numero, Historia.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(Numero, Historia.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(\"Training and Validation Loss on Dataset\", **title_font)\n",
    "    plt.xlabel(\n",
    "        f\"Epoch {EPOCHS} Batch Size {BS} Label {label_size} Data {image_per_label}\", **axis_font)\n",
    "    plt.ylabel(\"Loss\", **axis_font)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.savefig(\n",
    "        f\"../Model/{MODEL_NAME}/figure_loss_{MODEL_NAME}_label{label_size}_data{image_per_label}_e{EPOCHS}_bs{BS}.png\", dpi=600)\n",
    "\n",
    "\n",
    "# Print classification report to csv\n",
    "def print_class_reports(tes, predictions, target_names, MODEL_NAME, label_size, image_per_label, EPOCHS, BS):\n",
    "    report = classification_report(\n",
    "        tes, predictions, target_names=target_names, output_dict=True)\n",
    "    dataframe = pd.DataFrame(report).transpose()\n",
    "    dataframe.to_csv(\n",
    "        f\"../Model/{MODEL_NAME}/reports_{MODEL_NAME}_label{label_size}_data{image_per_label}_e{EPOCHS}_bs{BS}.csv\")\n",
    "    print(classification_report(tes, predictions, target_names=target_names))\n",
    "\n",
    "\n",
    "# print confusion matrix and visualize it\n",
    "def print_conf_matrix(tes, predictions, target_names, MODEL_NAME, label_size, image_per_label, EPOCHS, BS):\n",
    "    confusion_mtx = confusion_matrix(tes, predictions)\n",
    "    plt.figure()\n",
    "    sns.heatmap(confusion_mtx, xticklabels=target_names, yticklabels=target_names,\n",
    "                # annot=True,\n",
    "                fmt='g',\n",
    "                cbar_kws={'label': 'Individual Image'},\n",
    "                )\n",
    "    plt.title(\"Confusion Matrix on Prediction\", **title_font)\n",
    "    plt.xlabel('Prediction', **axis_font)\n",
    "    plt.xticks(fontsize=4)\n",
    "    plt.yticks(fontsize=4)\n",
    "    plt.ylabel('Label', **axis_font)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f\"../Model/{MODEL_NAME}/confusion_matrix_{MODEL_NAME}_label{label_size}_data{image_per_label}_e{EPOCHS}_bs{BS}.png\", dpi=600)\n",
    "    print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-juvenile",
   "metadata": {},
   "source": [
    "## PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Constant\n",
    "BS = 10\n",
    "EPOCHS = 150\n",
    "MODEL_NAME = \"RESNET50\"\n",
    "LEARNING_RATE = 0.001\n",
    "SPLIT_SIZE = \"\"\n",
    "\n",
    "print(\"[INFO] Hyperparameter:\")\n",
    "print(\"Epoch: \" + str(EPOCHS))\n",
    "print(\"Learning rate: \" + str(LEARNING_RATE))\n",
    "print(\"Batch Size: \" + str(BS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of train and test dataset\n",
    "training_dataset = f\"../Dataset/SplittedDataset{SPLIT_SIZE}/training_data\"\n",
    "list_training = list(os.listdir(training_dataset))\n",
    "testing_dataset = f\"../Dataset/SplittedDataset{SPLIT_SIZE}/testing_data\"\n",
    "list_testing = list(os.listdir(testing_dataset))\n",
    "\n",
    "label_size = len(list_training)\n",
    "print(\"Label Size:\", label_size)\n",
    "image_per_label = len(os.listdir(f\"{training_dataset}/{list_training[0]}\"))\n",
    "print(\"Image Per Label:\", image_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ TRAIN AND TEST DATA\n",
    "X_train, y_train, le_train = train_data(training_dataset)\n",
    "X_test, y_test, le_test = test_data(testing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-iraqi",
   "metadata": {},
   "source": [
    "## BUILD AND TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL\n",
    "model = resnet50(label_size)\n",
    "\n",
    "# SUMMARY MODEL\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE MODEL\n",
    "adam = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Initiate Callbacks\n",
    "my_callbacks = my_callbacks(MODEL_NAME, label_size,\n",
    "                            image_per_label, EPOCHS, BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate start time\n",
    "start_time = time.time()\n",
    "\n",
    "# TRAIN MODEL\n",
    "Historia = model.fit(X_train, y_train, validation_data=(\n",
    "    X_test, y_test), callbacks=my_callbacks, epochs=EPOCHS, batch_size=BS)\n",
    "\n",
    "# end time\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-packet",
   "metadata": {},
   "source": [
    "## EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_my_model(MODEL_NAME, label_size, image_per_label, EPOCHS, BS)\n",
    "\n",
    "results = model.evaluate(X_test, y_test, batch_size=BS)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.argmax(x) for x in model.predict(X_test, batch_size=BS)]\n",
    "tes = [np.argmax(y) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print_class_reports(tes, predictions, le_test.classes_, MODEL_NAME,\n",
    "                    label_size, image_per_label, EPOCHS, BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "print_conf_matrix(tes, predictions, le_test.classes_, MODEL_NAME,\n",
    "                  label_size, image_per_label, EPOCHS, BS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-ireland",
   "metadata": {},
   "source": [
    "## OBSERVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "visualize_accuracy(Historia, MODEL_NAME,\n",
    "                   label_size, image_per_label, EPOCHS, BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "visualize_loss(Historia, MODEL_NAME,\n",
    "               label_size, image_per_label, EPOCHS, BS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
